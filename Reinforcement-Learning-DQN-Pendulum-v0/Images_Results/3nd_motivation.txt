    def build_model(self):
        model = Sequential()
        model.add(Dense(64, input_shape=(self.state_space,), activation='relu'))
        model.add(Dense(64, activation='relu'))
        model.add(Dense(32, activation='relu'))         		  model.add(Dense(self.action_space, activation='linear'))
        model.compile(loss='mse', optimizer=adam(lr=self.learning_rate))  #loss = mean sqaured error, optimizer = adam
        return model

Results
ep = 200 score = 24 reward = 160
ep = 150 score = 25  reward = 161
ep = 100 score = 24 reward = 160
ep = 50 score =  24 reward = 150
ep = 0 score = 20 reward = -8
